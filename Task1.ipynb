{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf5236a",
   "metadata": {},
   "source": [
    "# Task 1: Dataset Exploration\n",
    "Create a summary table: participants, time per participant, demographics, total labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a857775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec9409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT exists: True\n",
      "Subfolders:\n",
      " - wisdm-dataset\\.activity_key.txt.swp\n",
      " - wisdm-dataset\\activity_key.txt\n",
      " - wisdm-dataset\\arffmagic-master\n",
      " - wisdm-dataset\\arff_files\n",
      " - wisdm-dataset\\change_raw_act.pl\n",
      " - wisdm-dataset\\raw\n",
      " - wisdm-dataset\\README.txt\n",
      "\n",
      "RAW subfolders:\n",
      " - wisdm-dataset\\raw\\phone\n",
      " - wisdm-dataset\\raw\\watch\n",
      " - wisdm-dataset\\raw\\phone\\accel\n",
      " - wisdm-dataset\\raw\\phone\\gyro\n",
      " - wisdm-dataset\\raw\\watch\\accel\n",
      " - wisdm-dataset\\raw\\watch\\gyro\n",
      "\n",
      "ARFF subfolders:\n",
      " - wisdm-dataset\\arff_files\\phone\n",
      " - wisdm-dataset\\arff_files\\watch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - wisdm-dataset\\arff_files\\phone\\accel\n",
      " - wisdm-dataset\\arff_files\\phone\\gyro\n",
      " - wisdm-dataset\\arff_files\\watch\\accel\n",
      " - wisdm-dataset\\arff_files\\watch\\gyro\n"
     ]
    }
   ],
   "source": [
    "# get paths, check validity\n",
    "DATA_ROOT = Path(\"wisdm-dataset\")\n",
    "RAW_DIR = DATA_ROOT / \"raw\"\n",
    "ARFF_DIR = DATA_ROOT / \"arff_files\"\n",
    "\n",
    "print(\"DATA_ROOT exists:\", DATA_ROOT.exists())\n",
    "print(\"Subfolders:\")\n",
    "for p in DATA_ROOT.iterdir():\n",
    "    print(\" -\", p)\n",
    "\n",
    "print(\"\\nRAW subfolders:\")\n",
    "for p in RAW_DIR.rglob(\"*\"):\n",
    "    if p.is_dir():\n",
    "        print(\" -\", p)\n",
    "\n",
    "print(\"\\nARFF subfolders:\")\n",
    "for p in ARFF_DIR.rglob(\"*\"):\n",
    "    if p.is_dir():\n",
    "        print(\" -\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f45d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean data\n",
    "def load_raw_sensor_data(device=\"watch\", sensor=\"accel\"):\n",
    "    \"\"\"\n",
    "    Load all raw files for a given device/sensor pair into a single DataFrame.\n",
    "\n",
    "    device: \"phone\" or \"watch\"\n",
    "    sensor: \"accel\" or \"gyro\"\n",
    "    \"\"\"\n",
    "    sensor_dir = RAW_DIR / device / sensor\n",
    "    if not sensor_dir.exists():\n",
    "        raise FileNotFoundError(f\"Sensor directory does not exist: {sensor_dir}\")\n",
    "\n",
    "    all_files = sorted(sensor_dir.glob(f\"data_*_{sensor}_{device}.txt\"))\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"No data files found in {sensor_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for f in all_files:\n",
    "        df = pd.read_csv(\n",
    "            f,\n",
    "            header=None,\n",
    "            names=[\"subject_id\", \"activity\", \"timestamp\", \"x\", \"y\", \"z_raw\"],\n",
    "            sep=\",\",\n",
    "            engine=\"python\"\n",
    "        )\n",
    "\n",
    "        # remove trailing ;\n",
    "        df[\"z\"] = df[\"z_raw\"].astype(str).str.replace(\";\", \"\", regex=False).astype(float)\n",
    "        df = df.drop(columns=[\"z_raw\"])\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c7815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null or bad values in the dataset\n",
    "VALID_ACTIVITIES = set(list(\"ABCDEFGHIJKLMOPQRS\"))  # Aâ€“S without N\n",
    "\n",
    "def check_dataframe_quality(df, name=\"data\"):\n",
    "    print(f\"\\n=== Quality report: {name} ===\")\n",
    "\n",
    "    # shape of data\n",
    "    print(f\"Rows: {len(df):,}, Columns: {df.shape[1]}\")\n",
    "\n",
    "    print(\"\\nColumn dtypes:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # number of null or nan values\n",
    "    print(\"\\nNull / NaN counts:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "    # number of infinity values\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        inf_mask = np.isinf(df[numeric_cols].to_numpy())\n",
    "        n_inf = inf_mask.sum()\n",
    "        print(f\"\\nNumber of infinite values in numeric columns: {n_inf}\")\n",
    "        if n_inf > 0:\n",
    "            col_inf_counts = np.isinf(df[numeric_cols]).sum()\n",
    "            print(\"Inf counts per numeric column:\")\n",
    "            print(col_inf_counts)\n",
    "    else:\n",
    "        print(\"\\nNo numeric columns detected for inf check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff02200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Quality report: watch_accel ===\n",
      "Rows: 3,777,046, Columns: 6\n",
      "\n",
      "Column dtypes:\n",
      "subject_id      int64\n",
      "activity       object\n",
      "timestamp       int64\n",
      "x             float64\n",
      "y             float64\n",
      "z             float64\n",
      "dtype: object\n",
      "\n",
      "Null / NaN counts:\n",
      "subject_id    0\n",
      "activity      0\n",
      "timestamp     0\n",
      "x             0\n",
      "y             0\n",
      "z             0\n",
      "dtype: int64\n",
      "\n",
      "Number of infinite values in numeric columns: 0\n",
      "\n",
      "=== Quality report: watch_gyro ===\n",
      "Rows: 3,440,342, Columns: 6\n",
      "\n",
      "Column dtypes:\n",
      "subject_id      int64\n",
      "activity       object\n",
      "timestamp       int64\n",
      "x             float64\n",
      "y             float64\n",
      "z             float64\n",
      "dtype: object\n",
      "\n",
      "Null / NaN counts:\n",
      "subject_id    0\n",
      "activity      0\n",
      "timestamp     0\n",
      "x             0\n",
      "y             0\n",
      "z             0\n",
      "dtype: int64\n",
      "\n",
      "Number of infinite values in numeric columns: 0\n"
     ]
    }
   ],
   "source": [
    "# watch data quality checks\n",
    "watch_accel = load_raw_sensor_data(device=\"watch\", sensor=\"accel\")\n",
    "watch_gyro = load_raw_sensor_data(device=\"watch\", sensor=\"gyro\")\n",
    "\n",
    "check_dataframe_quality(watch_accel, name=\"watch_accel\")\n",
    "check_dataframe_quality(watch_gyro, name=\"watch_gyro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for time per participant\n",
    "def time_per_participant_from_counts(df, sampling_rate=20.0):\n",
    "    counts = df.groupby(\"subject_id\").size().rename(\"n_samples\")\n",
    "    summary = counts.to_frame()\n",
    "    \n",
    "    summary[\"time_sec\"] = summary[\"n_samples\"] / sampling_rate\n",
    "    summary[\"time_min\"] = summary[\"time_sec\"] / 60.0\n",
    "    summary[\"time_hr\"] = summary[\"time_sec\"] / 3600.0\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "824ae39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Participant summary: watch_accel ===\n",
      "Number of participants: 51\n",
      "Number of unique labels: 18\n",
      "Average minutes per participant: 61.72\n"
     ]
    }
   ],
   "source": [
    "# summary of data\n",
    "def summarize_participants(df, name=\"data\"):\n",
    "    print(f\"\\n=== Participant summary: {name} ===\")\n",
    "    participants = df[\"subject_id\"].unique()\n",
    "    print(f\"Number of participants: {len(participants)}\")\n",
    "\n",
    "    unique_labels = sorted(watch_accel[\"activity\"].unique())\n",
    "    print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "\n",
    "    avg_min = time_per_participant_from_counts(df)[\"time_min\"].mean()\n",
    "    print(\"Average minutes per participant:\", round(avg_min, 2))\n",
    "\n",
    "# Example\n",
    "summarize_participants(watch_accel, name=\"watch_accel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
